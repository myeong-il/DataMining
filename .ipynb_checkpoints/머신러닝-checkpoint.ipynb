{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. \n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib.request\n",
    "def create_url(api_node, search_text, start_num, disp_num):\n",
    "   \n",
    "    base = \"https://openapi.naver.com/v1/search\"\n",
    "    node = \"/\" + api_node + \".json\"\n",
    "    param_query = \"?query=\" + urllib.parse.quote(search_text)\n",
    "    param_start = \"&start=\" + str(start_num)\n",
    "    param_disp = \"&display=\" + str(disp_num)\n",
    "    \n",
    "    return base + node + param_query + param_start + param_disp\n",
    "\n",
    "def delete_tag(input_str):\n",
    "    input_str = input_str.replace(\"<b>\", \"\")\n",
    "    input_str = input_str.replace(\"</b>\", \"\")\n",
    "    return input_str\n",
    "\n",
    "def get_dataframe(url):\n",
    "    \n",
    "    client_id =\"8wjANk3RDs72XRGaLU9V\"\n",
    "    client_secret=\"plRX5zb4l4\"   \n",
    "    \n",
    "    \n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\", client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\", client_secret)\n",
    "    \n",
    "    response = urllib.request.urlopen(request)\n",
    "\n",
    "    result = json.loads(response.read().decode('utf-8'))\n",
    "    \n",
    "    end_num = result['display']\n",
    "    \n",
    "    titles = [delete_tag(result['items'][n]['title']) for n in range(end_num)]\n",
    "    authors = [result['items'][n]['author'] for n in range(end_num)]\n",
    "    pubdates = [result['items'][n]['pubdate'] for n in range(end_num)]\n",
    "    prices = [result['items'][n]['price'] for n in range(end_num)]\n",
    "    \n",
    "    return pd.DataFrame({'책제목':titles, '저자':authors, '출판일':pubdates, '가격':prices})\n",
    "\n",
    "url = create_url(\"book\", \"파이썬\", 1, 10)\n",
    "\n",
    "a = get_dataframe(url)\n",
    "a\n",
    "\n",
    "a2020 = a[a['출판일'].str.contains('20**')]\n",
    "\n",
    "a2020['가격'] = a2020['가격'].astype('int')\n",
    "\n",
    "a2020.describe()\n",
    "\n",
    "2.\n",
    "a = pd.read_csv('supplier_data.csv')\n",
    "a['Cost'] = a['Cost'].str.strip('$').astype('float')\n",
    "a.describe()\n",
    "Part number : 4684.833333 Cost : 475.833333\n",
    "\n",
    "3.\n",
    "file = open('write.txt', 'w', encoding='utf-8')\n",
    "for i in range(1,11):\n",
    "    if i%2 == 0:\n",
    "        content = \"%d는 1부터 10까지 숫자중 짝수입니다.\\n\" %i\n",
    "        file.write(content)\n",
    "    else:\n",
    "        content = \"%d는 1부터 10까지 숫자중 홀수입니다.\\n\" %i\n",
    "        file.write(content)\n",
    "file.close()\n",
    "\n",
    "4.\n",
    "import os\n",
    "import glob\n",
    "\n",
    "f1=[]\n",
    "path = \"C://temp1\"\n",
    "\n",
    "for file in glob.glob(os.path.join(path,'q*.txt')):\n",
    "    with open(file ,'r' , newline='') as filereader:\n",
    "        for row in filereader:\n",
    "            contents=row.split()\n",
    "            for i in contents:\n",
    "                contents=i.strip()\n",
    "                f1.append(contents)\n",
    "from collections import Counter\n",
    "word_counts = Counter(f1)\n",
    "dict(word_counts)\n",
    "wc = sorted(word_counts.items(),key=lambda count:count[1], reverse=True) \n",
    "wc\n",
    "5.\n",
    "\n",
    "6.\n",
    "dict_wc = dict(wc[1:4])\n",
    "sum(dict_wc.values()) 17\n",
    "\n",
    "7.\n",
    "x = [100, 40, 50, 40, 50, 60, 40, 50, 50, 80, 50, 60, 80, 50, 40, 30, 60, 70, 50, 40, 30, 60]\n",
    "def mean(x):\n",
    "    return sum(x) / len(x)\n",
    "mean(x)\n",
    "\n",
    "def de_mean(y):\n",
    "    y_bar = mean(y)\n",
    "    return [i-y_bar for i in y]\n",
    "y = de_mean(x)\n",
    "y[3]\n",
    "\n",
    "x1=[1,2]\n",
    "x2=[3,4]\n",
    "def dot(x1, x2):\n",
    "    return sum(i*j for i, j in zip(x1,x2))\n",
    "\n",
    "def sum_of_squares(x1):\n",
    "    return dot(x1,x1)\n",
    "\n",
    "def variance(x):\n",
    "    n = len(x)\n",
    "    dev = de_mean(x)\n",
    "    return sum_of_squares(dev) / n\n",
    "\n",
    "x2 = [3,4]\n",
    "variance(x2) 0.25\n",
    "\n",
    "variance(x)\n",
    "\n",
    "8.\n",
    "import pandas as pd\n",
    "\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\"\n",
    "\n",
    "df = pd.read_csv(url, sep=r'\\s+', header=None)\n",
    "df.columns = ['CRIM', 'ZN', 'INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIP','B','LSTAT','MEDV']\n",
    "df.columns = df.columns.str.lower()\n",
    "df.shape\n",
    "\n",
    "var1 = ['rm','age','dis','medv']\n",
    "r = df[var1].corr().iloc[0,3]\n",
    "r.round(3)\n",
    "0.695\n",
    "\n",
    "9.\n",
    "\n",
    "1) raw_data.groupby('pclass').mean() 0.619195\n",
    "2) raw_data.groupby('pclass').mean() 24.816367\n",
    "3) raw_data.corr() -0.312469\n",
    "4) \n",
    "a = raw_data[raw_data['age'] <=10]\n",
    "a.describe() 0.581395\n",
    "5) \n",
    "boat_survivors = raw_data[raw_data['boat'].notnull()]\n",
    "boat_survivors['survived'].value_counts() 477\n",
    "6) \n",
    "conversion_rare = lambda x: x.split(',')[1].split('.')[0].strip()\n",
    "\n",
    "raw_data['title'] = raw_data['name'].map(conversion_rare)\n",
    "\n",
    "raw_data['title'] = raw_data['title'].replace('Mlle', 'Miss')\n",
    "raw_data['title'] = raw_data['title'].replace('Ms', 'Miss')\n",
    "raw_data['title'] = raw_data['title'].replace('Mme', 'Mrs')\n",
    "\n",
    "Rare = ['Lady','the Countess','Countess','Capt', 'Master',\n",
    "        'Col','Don','Dr','Major','Rev','Sir','Jonkheer', 'Dona']\n",
    "for each in Rare:\n",
    "    raw_data['title'] = raw_data['title'].replace(each, 'Rare')\n",
    "\n",
    "raw_data[['title', 'survived']].groupby(['title'], as_index=False).mean()\n",
    "0.162483\n",
    "\n",
    "10.\n",
    "arr = [[1, 2, 3, 4],[5, 6, 7, 8]]\n",
    "\n",
    "np_arr = np.array(arr)\n",
    "\n",
    "np_arr.reshape(2,4) + 10\n",
    "\n",
    "11.\n",
    "np_arr = np.array(range(0,20))\n",
    "np_arr_2d = np_arr.reshape(5,4)\n",
    "np_arr_2d1 = np_arr.reshape(5,-1)\n",
    "np_arr_3rd = np_arr_2d + np_arr_2d1\n",
    "np_arr_3 = np_arr_3rd.flatten()\n",
    "np_arr_3.sum()\n",
    "380\n",
    "\n",
    "12.\n",
    "Hong1 = [80,90,20,20]\n",
    "Hong2 = [70,80,20,20]\n",
    "Hong_S = Hong1+Hong2  # [80, 90, 20, 20, 70, 80, 20, 20]\n",
    "Hong_S = np.array(Hong1) + np.array(Hong2) #[150, 170, 40, 40]\n",
    "Hong_S = sum(Hong1+Hong2) or sum(np.array(Hong1) + np.array(Hong2)) # 400\n",
    "print(Hong_S)\n",
    "\n",
    "13.\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "df1=pd.read_csv('tmdb_5000_credits.csv')\n",
    "df2=pd.read_csv('tmdb_5000_movies.csv')\n",
    "df1.columns = ['id','tittle','cast','crew']\n",
    "df2= df2.merge(df1,on='id')\n",
    "C= df2['vote_average'].mean() # 즉, 모든 영화에 대한 평점의 평균\n",
    "C #6.092171559442011\n",
    "\n",
    "#id 기준 내림차순정렬할때\n",
    "df2_id = df2.sort_values(by='id', ascending=False)\n",
    "print(df2_id['vote_count'][0:3].sum()) # 0 \n",
    "\n",
    "#id 기준 오름차순정렬할때\n",
    "df2_id = df2.sort_values(by='id', axis=0)\n",
    "print(df2_id['vote_count'][0:3].sum()) # 13276 \n",
    "\n",
    "#id 기준 정렬 안할때\n",
    "print(df2['vote_count'][0:3].sum()) #20766\n",
    "\n",
    "m= df2['vote_count'].quantile(0.99)\n",
    "print(len(df2[df2['vote_count']>m]))\n",
    "\n",
    "df2[df2['vote_count']>m].describe()\n",
    "\n",
    "q_movies = df2.copy().loc[df2['vote_count'] >= m]\n",
    "q_movies.shape\n",
    "\n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = x['vote_count']\n",
    "    R = x['vote_average']\n",
    "    return ((v/(v+m) * R) + (m/(m+v) * C))\n",
    "\n",
    "q_movies['score'] = q_movies.apply(weighted_rating, axis=1)\n",
    "q_movies['score']\n",
    "\n",
    "q_movies = q_movies.sort_values(by='score', ascending=False)\n",
    "\n",
    "q_movies[['title', 'vote_count', 'vote_average', 'score']].head(10)\n",
    "\n",
    "df2_id\n",
    "\n",
    "14.\n",
    "from collections import Counter\n",
    "DB = [\n",
    "[\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "[\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "[\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "[\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "[\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "[\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "[\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "[\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "[\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "[\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "[\"statistics\", \"R\", \"statsmodels\"],\n",
    "[\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "[\"pandas\", \"R\", \"Python\"],\n",
    "[\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "[\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]\n",
    "\n",
    "\n",
    "popular_interests = Counter(interest_word\n",
    "                                             for users in DB\n",
    "                                           for interest_word in users).most_common()\n",
    "\n",
    "def most_popular_new_interests(user_interests, max_results=5):\n",
    "    suggestions = [(interest,frequency)\n",
    "         for interest, frequency in popular_interests\n",
    "         if interest not in DB]\n",
    "    return suggestions[:max_results] \n",
    "\n",
    "most_popular_new_interests(DB, max_results=5)\n",
    "\n",
    "\n",
    "id2=DB[1]\n",
    "\n",
    "most_popular_new_interests(id2, 2)\n",
    "[('Python', 4), ('R', 4)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
